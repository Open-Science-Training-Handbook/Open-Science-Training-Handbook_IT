
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Revisione tra pari aperta, metriche e valutazione · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="09OpenSciencePolicies.html" />
    
    
    <link rel="prev" href="07CollaborativePlatforms.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Readme
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../01Introduction/">
            
                <a href="../01Introduction/">
            
                    
                    Introduzione
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="./">
            
                <a href="./">
            
                    
                    I principi fondamentali della Scienza Aperta
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="01OpenConceptsAndPrinciples.html">
            
                <a href="01OpenConceptsAndPrinciples.html">
            
                    
                    Concetti e principi "open"
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="02OpenResearchDataAndMaterials.html">
            
                <a href="02OpenResearchDataAndMaterials.html">
            
                    
                    Dati di ricerca e materiali aperti
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="03OpenResearchSoftwareAndOpenSource.html">
            
                <a href="03OpenResearchSoftwareAndOpenSource.html">
            
                    
                    Software aperto per la ricerca e open source
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="04ReproducibleResearchAndDataAnalysis.html">
            
                <a href="04ReproducibleResearchAndDataAnalysis.html">
            
                    
                    La riproducibilità della ricerca e l'analisi dei dati
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="05OpenAccessToPublishedResearchResults.html">
            
                <a href="05OpenAccessToPublishedResearchResults.html">
            
                    
                    Accesso aperto ai risultati della ricerca pubblicati
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="06OpenLicensingAndFileFormats.html">
            
                <a href="06OpenLicensingAndFileFormats.html">
            
                    
                    Licenze e formato dei file
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="07CollaborativePlatforms.html">
            
                <a href="07CollaborativePlatforms.html">
            
                    
                    Le piattaforme collaborative
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.8" data-path="08OpenPeerReviewMetricsAndEvaluation.html">
            
                <a href="08OpenPeerReviewMetricsAndEvaluation.html">
            
                    
                    Revisione tra pari aperta, metriche e valutazione
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="09OpenSciencePolicies.html">
            
                <a href="09OpenSciencePolicies.html">
            
                    
                    Politiche e Scienza Aperta
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="10CitizenScience.html">
            
                <a href="10CitizenScience.html">
            
                    
                    Citizen Science - la scienza di tutti
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="11OpenEducationalResources.html">
            
                <a href="11OpenEducationalResources.html">
            
                    
                    Risorse aperte per l'insegnamento e l'apprendimento
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="12OpenAdvocacy.html">
            
                <a href="12OpenAdvocacy.html">
            
                    
                    L'advocacy aperta
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../03OnLearningAndTraining/">
            
                <a href="../03OnLearningAndTraining/">
            
                    
                    Processi di apprendimento e di formazione
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../04OrganizationalAspects/">
            
                <a href="../04OrganizationalAspects/">
            
                    
                    Aspetti organizzativi
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../05ExamplesAndPracticalGuidance/">
            
                <a href="../05ExamplesAndPracticalGuidance/">
            
                    
                    Esempi & guida pratica: adotta, adatta, sviluppa
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../06Glossary/">
            
                <a href="../06Glossary/">
            
                    
                    Glossario
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../07References/">
            
                <a href="../07References/">
            
                    
                    Bibliografia
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../08AboutTheAuthorsAndFacilitators/">
            
                <a href="../08AboutTheAuthorsAndFacilitators/">
            
                    
                    Gli autori
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../09AboutItalianTranslatorsRevisioners/">
            
                <a href="../09AboutItalianTranslatorsRevisioners/">
            
                    
                    Traduttori e Revisori che hanno collaborato alla versione italiana del manuale
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Revisione tra pari aperta, metriche e valutazione</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h2 id=""><img src="../Images/Icons/peer_review.png" width="300" height="300"></h2>
<h2 id="8-revisione-tra-pari-aperta-metriche-e-valutazione">8. Revisione tra pari aperta, metriche e valutazione</h2>
<h3 id="di-che-cosa-si-tratta">Di che cosa si tratta?</h3>
<p>Essere un ricercatore significa trovarsi continuamente sotto giudizio degli altri. L&#x2019;Accademia &#xE8; &#x201C;un&#x2019;economia del prestigio&#x201D; in cui il valore degli accademici &#xE8; basato sulle valutazioni circa il livello di stima di cui godono loro stessi e i loro contributi presso i pari, i decisori e altri (<a href="https://doi.org/10/fqrkft" target="_blank">Blackmore and Kandiko, 2011</a>). In questa sezione sar&#xE0; quindi opportuno distinguere tra la valutazione di un lavoro di ricerca e la valutazione del ricercatore. Sia la ricerca, sia il ricercatore sono sottoposti a valutazione attraverso due metodi principali: la revisione tra pari (peer review) e le metriche, il primo qualitativo e il secondo quantitativo.</p>
<p>La revisione tra pari &#xE8; usata, in primo luogo, per valutare l&#x2019;appropriatezza dei prodotti della ricerca. &#xC8; il meccanismo formale di garanzia di qualit&#xE0; per il quale i manoscritti scientifici (per esempio, articoli su riviste, libri, progetti per finanziamenti e contributi in convegni) vengono sottoposti allo scrutinio di altri, i cui commenti e giudizi sono poi usati per migliorare i lavori e prendere la decisione finale sulla loro accettazione (per la pubblicazione, la concessione del finanziamento o l&#x2019;inserimento nel programma di un convegno). La revisione tra pari aperta (Open Peer Review) ha un significato diverso per persone e comunit&#xE0; differenti ed &#xE8; stata definita come &#x201C;termine generico per indicare una serie di modalit&#xE0; similari in cui i modelli di peer review possono essere adattati in accordo con gli obiettivi della Scienza Aperta&#x201D; (<a href="https://doi.org/10/gc5sjh" target="_blank">Ross-Hellauer, 2017</a>). I tratti peculiari della revisione tra pari aperta sono le &#x201C;identit&#xE0; aperte&#x201D;: autori e revisori conoscono le rispettive reciproche identit&#xE0; (referaggio non alla cieca dall&#x2019;inglese &#x2018;non blinded&#x2019;) e la &#x201C;relazione di referaggio aperta&#x201D; per cui si prevedere che i risultati della peer review vengano pubblicati insieme al corrispondente articolo. Queste caratteristiche possono ma non devono essere necessariamente combinate; possono altres&#xEC; essere integrate con altre pratiche innovative come la &#x201C;partecipazione aperta&#x201D; che prevede che tutti i membri dell&#x2019;intera comunit&#xE0; scientifica possano contribuire al processo di revisione; l&#x2019;&#x201C;interazione aperta&#x201D; che consente ed incoraggia una discussione bi-direzionale tra autori e revisori e/o tra revisori; &#x201C;l&#x2019;anteprima aperta del manoscritto&#x201D; in cui i manoscritti vengono resi immediatamente disponibili prima di qualsiasi processo formale di referaggio (sia internamente come parte del flusso di lavoro della rivista sia esternamente attraverso gli archivi preprint).</p>
<p>Una volta passate attraverso il processo di revisione aperta tra pari, le pubblicazioni scientifiche diventano poi spesso la prima forma di misurazione del lavoro di un ricercatore (da qui il modo di dire &quot;o si pubblica o  si muore&quot;(dall&apos;inglese: &quot;publish or perish&quot;). Tuttavia, giudicare la qualit&#xE0; di una pubblicazione &#xE8; difficile e soggettivo. Nonostante alcuni esercizi di valutazione generici come il Research Excellence Framework (Regno Unito) utilizzino la revisione aperta tra pari, la valutazione si basa spesso sulle metriche, come ad esempio, il numero delle citazioni (h-index), o anche il livello di influenza percepito della rivista dove si &#xE8; pubblicato (espresso dal suo fattore di impatto). L&#x2019;uso predominante di tali metriche e il modo in cui queste possono alterare l&apos;attribuzione degli incentivi sono stati messi in evidenza in alcune dichiarazioni come il <a href="http://www.leidenmanifesto.org/" target="_blank">Manifesto di Leiden</a> e la  <a href="https://sfdora.org/" target="_blank">Declaration on Research Assessment (DORA) di San Francisco</a>.</p>
<p>Negli ultimi anni si &#xE8; cominciato a discutere sulle cosiddette <a href="https://www.altmetric.com" target="_blank">metriche alternative</a> o &#x201C;altmetrics&#x201D; contestualmente al dibattito su come misurare adeguatamente i risultati della ricerca attraverso l&#x2019;integrazione -nel conteggio delle citazioni- di altri strumenti online per misurare l&#x2019;impatto della ricerca, come i salvataggi nei bookmark, i link, i post nei blog, i tweet, i &quot;like&quot;, le condivisioni, la visibilit&#xE0; sugli organi di stampa e similari. Tutte le problematiche relative alle metriche sono riconducibili al fatto che a produrle sono entit&#xE0; commerciali (ad esempio, Clarivate Analytics ed Elsevier) che, basandosi su sistemi proprietari, possono creare problemi di trasparenza.</p>
<h2 id=""><img src="../Images/Icons/umbrella.png" width="150" height="150"></h2>
<h3 id="fondamentali">Fondamentali</h3>
<h4 id="la-revisione-tra-pari-aperta">La revisione tra pari aperta</h4>
<p>Introdotta nel XVII secolo dalla Royal Society di Londra (1662) e dall&#x2019;Acad&#xE9;mie Royale des Sciences di Parigi (1699) come privilegio del mondo scientifico all&apos;auto-censura anzicch&#xE8; per volere della Chiesa, ci sono voluti molti anni prima che la revisione tra pari si affermasse adeguatamente. La revisione tra pari, come meccanismo formale, &#xE8; molto pi&#xF9; recente di quanto si possa pensare. La rivista &#x201C;Nature&#x201D;, ad esempio, l&#x2019;ha introdotta solo nel 1967. Sebbene, secondo alcuni studi, i ricercatori sembrino apprezzare la revisione tra pari, risulta altres&#xEC; che siano dell&#x2019;opinione che potrebbe funzionare anche meglio. Ci sono spesso lamentele sui tempi troppo lunghi di revisione, sulla sua incongruenza nonch&#xE9; a volte di inefficacia nel riconoscere gli errori e sull&#x2019;anonimato che pu&#xF2; celare parzialit&#xE0;. La revisione tra pari aperta (OPR Open peer review) mira pertanto ad apportare maggiore trasparenza e partecipazione al processo formale ed informale della revisione tra pari. Diventare un revisore offre al ricercatore l&#x2019;opportunit&#xE0; di essere coinvolto in ricerche innovative, di costruire reti e competenze accademiche e di raffinare le proprie abilit&#xE0; di scrittura. &#xC8; un elemento cruciale per il controllo della qualit&#xE0; del lavoro accademico. Generalmente, per&#xF2;, i ricercatori non ricevono spesso una preparazione formale su come fare una revisione. Anche laddove i ricercatori si sentano sicuri con la revisione tra pari tradizionale, le molte forme di revisione tra pari aperta presentano, tuttavia, nuove sfide e nuove opportunit&#xE0;. Poich&#xE9; la OPR copre un&#x2019;ampia variet&#xE0; di pratiche, ci sono molte considerazioni di cui i revisori e gli autori devono tenere conto.</p>
<h2 id=""><img src="../Images/02 Open Science Basics/02_open_peer_review.png"></h2>
<p>Riguardo alla valutazione, attualmente i riconoscimenti e le metriche nella scienza e nelle attivit&#xE0; di ricerca non sono (ancora) in linea con la Scienza Aperta. Le metriche usate per valutare la ricerca (ad esempio il fattore di impatto di una rivista scientifica h-index) non misurano - e di conseguenza non premiano - le pratiche di ricerca aperta. L&#x2019;attivit&#xE0; di revisione tra pari aperta non &#xE8; sempre riconosciuta come &#x201C;attivit&#xE0; scientifica&#x201D; relativamente alle progressioni di carriera (ad esempio, in molti casi, gli esperti che valutano i progetti di finanziamento non considerano nemmeno le revisioni tra pari aperte pi&#xF9; brillanti come degli oggetti scientifici di per s&#xE9;). Inoltre, molte metriche di valutazione - specialmente certe tipologie di indici bibliometrici - non sono cos&#xEC; aperti e trasparenti come la comunit&#xE0; scientifica auspicherebbe.</p>
<p>In questo contesto e, nella migliore delle ipotesi, praticare la Scienza Aperta &#xE8; percepito come un&#x2019;altra incombenza fine a s&#xE8; stessa, senza alcun riconoscimento. Nella peggiore delle ipotesi, &#xE8; considerato un danno e un ostacolo per accedere a possibili finanziamenti futuri e a promozioni per non parlare di avanzamenti di carriera. Un recente <a href="https://doi.org/10.2777/75255" target="_blank">Rapporto della Commissione Europea</a> (2017) ha riconosciuto che ci sono fondamentalmente due approcci all&#x2019;implementazione della Scienza Aperta e al modo in cui i riconoscimenti e la valutazione possono favorirla:</p>
<ol>
<li><p>Sostegno puro e semplice dell&#x2019;attuale stato dell&#x2019;arte incoraggiando maggiore apertura, costruendo metriche adatte e quantificando i prodotti;</p>
</li>
<li><p>Sperimentazione di pratiche alternative di ricerca e valutazione, dati aperti, scienza partecipativa e risorse di insegnamento e apprendimento aperte.</p>
</li>
</ol>
<p>Enti finanziatori ed istituzioni si stanno muovendo sempre di pi&#xF9; verso queste due direzioni, prendendo distanza, ad esempio, dai semplici conteggi numerici e includendo nei loro esercizi di valutazione resoconti e indicazioni sull&#x2019;impatto sociale. Altri passi che gli enti finanziatori stanno compiendo sono l&#x2019;inclusione nei bandi di altri tipi di prodotti della ricerca (come i manoscritti non referati) e il finanziamento di diverse tipologie di studi di ricerca (come gli studi sulla replicazione).</p>
<h2 id=""><img src="../Images/Icons/finish.png" width="150" height="150"></h2>
<h3 id="finalit&#xE0;-didattiche">Finalit&#xE0; didattiche:</h3>
<ol>
<li>Riconoscere gli elementi chiave della revisione aperta tra pari e i potenziali vantaggi e svantaggi.</li>
<li>Comprendere le differenze tra le diverse tipologie di metriche usate per valutare la ricerca e i ricercatori.</li>
<li>Partecipare al dibattito su come il modello di valutazione influenzi la maniera nella quale si fa ricerca.</li>
</ol>
<h3 id="componenti-chiave">Componenti chiave</h3>
<h2 id=""><img src="../Images/Icons/brain.png" width="150" height="150"></h2>
<h3 id="conoscenza">Conoscenza</h3>
<h4 id="revisione-tra-pari-aperta">Revisione tra pari aperta</h4>
<p>Sedi popolari per la revisione tra pari aperta, includono riviste scientifiche di editori, come Copernicus, Frontiers, BioMed Central, eLife e F1000research.</p>
<p>La revisione tra pari aperta, in tutte le sue diverse forme, ha molti potenziali vantaggi per revisori e autori:</p>
<ul>
<li><p>La revisione con identit&#xE0; aperte (non-cieca) favorisce una maggiore affidabilit&#xE0; tra i revisori e riduce le occasioni di parzialit&#xE0; e di conflitti di interesse non dichiarati.</p>
</li>
<li><p>Le relazioni di referaggio aperte aggiungono un altro livello di garanzia di qualit&#xE0;, permettendo alla comunit&#xE0; scientifica estesa di verificare le revisioni e analizzare il processo decisionale.</p>
</li>
<li><p>Si &#xE8; teorizzato che, se combinate, le identit&#xE0; aperte e le relazioni di referaggio aperte portano a revisioni qualitativamente migliori, in quanto il fatto di avere il proprio nome associato pubblicamente ad un lavoro o di vedere la propria revisione pubblicata incoraggia i revisori ad una maggiore accuratezza.</p>
</li>
<li><p>Le identit&#xE0; aperte e le relazioni di referaggio aperte consentono ai revisori di accrescere la reputazione pubblica del loro lavoro di revisione, incentivando in questo modo questa attivit&#xE0; essenziale e facendo in modo che il lavoro di revisione venga citato in altre pubblicazioni e tra le attivit&#xE0; utili all&#x2019;avanzamento di carriera legate alla promozione e al ruolo.</p>
</li>
<li><p>La partecipazione aperta potrebbe contribuire a superare i problemi associati alla selezione editoriale dei revisori (per esempio, pregiudizi, reti chiuse, elitarismo). In special modo per i ricercatori che all&#x2019;inizio della loro carriera non vengono invitati a fare revisioni, questi processi aperti potrebbero rappresentare un&#x2019;opportunit&#xE0; per costruire la loro reputazione nel mondo della ricerca e acquisire pratica esercitando nuove competenze.</p>
</li>
</ul>
<p>Potenziali trappole da tenere in considerazione:</p>
<ul>
<li><p>Le identit&#xE0; aperte rimuovono la condizione di anonimato per i revisori (singola cieca, single-blind) o tra gli autori e i revisori (doppia cieca, double-blind) che tradizionalmente sono state introdotte per contrastare pregiudizi sociali (sebbene l&#x2019;efficacia dell&#x2019;anonimato non sia stata provata). &#xC8; quindi importante che i revisori facciano attenta autocritica sulle proprie conclusioni per essere certi che i loro giudizi riflettano la qualit&#xE0; del manoscritto soltanto non lo stato, la storia o le affiliazioni dell&#x2019;autore o degli autori. Gli autori dovrebbero fare lo stesso quando ricevono i commenti della revisione da parte dei loro pari.</p>
</li>
<li><p>Fare e ricevere critiche &#xE8; spesso un processo carico di inevitabili reazioni emotive - gli autori e i revisori potrebbero soggettivamente concordare oppure essere in disaccordo su come presentare i risultati e/o su cosa necessiti di miglioramento, rettifica o correzione. Nelle identit&#xE0; aperte e/o nelle relazioni aperte, la trasparenza potrebbe esacerbare tali difficolt&#xE0;. &#xC8; quindi essenziale che i revisori assicurino di comunicare le loro osservazioni in modo chiaro e civile, cos&#xEC; da massimizzare le possibilit&#xE0; che vengano accolte come opinioni fondate da parte dell&#x2019;autore o degli autori.</p>
</li>
<li><p>L&#x2019;assenza di anonimato per i revisori nella revisione con identit&#xE0; aperte potrebbe minare il processo, scoraggiando i revisori dal fare critiche spietate, specialmente ai danni di colleghi con uno status pi&#xF9; alto.</p>
</li>
<li><p>Per concludere e, in considerazione dei punti appena messi in luce, la probabilit&#xE0; che potenziali revisori decidano di declinare l&#x2019;incarico di revisione aumenta. </p>
</li>
</ul>
<h4 id="le-metriche-aperte">Le metriche aperte</h4>
<p>La <a href="https://sfdora.org/" target="_blank">San Francisco Declaration on Research Assessment (DORA)</a> raccomanda di discostarsi dalle valutazioni che si basano sulle riviste scientifiche, di prendere in considerazione tutte le tipologie di prodotti della ricerca e di usare diverse forme di metriche e valutazioni narrative parallelamente. DORA &#xE8; stata firmata da migliaia di ricercatori, istituzioni, editori e enti finanziatori che si sono impegnati a mettere in pratica quanto previsto dalla dichiarazione. Il <a href="http://www.leidenmanifesto.org/" target="_blank">Manifesto di Leiden</a> fornisce una guida su come usare le metriche in maniera responsabile.</p>
<p>Per quanto riguarda le metriche alternative, <a href="http://altmetrics.org/manifesto/" target="_blank">Priem et al. (2010)</a> le consigliano per i seguenti vantaggi: raccolgono le citazioni pi&#xF9; velocemente; possono misurare l&#x2019;impatto anche di prodotti della ricerca diversi dalle pubblicazioni su rivista (per esempio, set di dati, codici, protocolli, post nei blog, tweet, ecc.); e possono fornire misure differenziate dell&#x2019;impatto per singoli oggetti. La tempestivit&#xE0; delle metriche alternative presenta un particolare vantaggio per i ricercatori a inizio carriera, per i quali l&#x2019;impatto della ricerca potrebbe non essere rispecchiato da un numero significativo di citazioni, ma per i quali comunque un avanzamento di carriera dipende dalle valutazioni positive. In aggiunta, le metriche alternative possono aiutare ad identificare una ricerca influente e le potenziali connessioni tra i ricercatori. Un recente rapporto presentato dal Gruppo di esperti in metriche alternative della Commissione Europea <a href="https://ec.europa.eu/research/openscience/pdf/report.pdf" target="_blank">(Wilsdon et al. (European Commission), 2017)</a>) ha identificato le criticit&#xE0; delle metriche alternative: la mancanza di robustezza e la suscettibilit&#xE0; al &#x201C;gioco d&#x2019;azzardo&#x201D;; il fatto che qualsiasi misura cessi di essere una buona misura quando diventa un obiettivo (Legge di Goodhard); la relativa mancanza di diffusione nei social media di alcune discipline e aree geografiche; e il doversi affidare ad entit&#xE0; commerciali per i dati di base.</p>
<h2 id=""><img src="../Images/Icons/gears.png" width="150" height="150"></h2>
<h3 id="compentenze">Compentenze</h3>
<p>Esercitazioni </p>
<ul>
<li><p>Ai partecipanti viene richiesto di lavorare in gruppo, ognuno composto da tre persone. Ogni partecipante scrive una sua personale revisione di un breve testo accademico.</p>
</li>
<li><p>Revisione di un articolo su un server pre-print</p>
</li>
<li><p>Utilizzo di un servizio gratuito di bibliometria o metriche alternative (ad esempio <a href="https://impactstory.org/" target="_blank">Impactstory</a>, <a href="https://paperbuzz.org/" target="_blank">Paperbuzz</a>, <a href="https://www.altmetric.com/products/free-tools/bookmarklet/" target="_blank">Altmetric bookmarklet</a>, <a href="https://www.dimensions.ai/" target="_blank">Dimensions.ai</a>) per la ricerca delle metriche di un articolo. I partecipanti devono quindi scrivere una breve spiegazione su come vengono esattamente calcolate le diverse metriche presentate da ciascun servizio (&#xE8; pi&#xF9; difficile di quanto si pensi; significa cercare di individuare la documentazione appropriata sulle metriche anche per i servizi apparentemente pi&#xF9; trasparenti).</p>
</li>
</ul>
<h2 id=""><img src="../Images/Icons/questions.png" width="150" height="150"></h2>
<h3 id="domande-intoppi-ed-equivoci-comuni">Domande, intoppi ed equivoci comuni</h3>
<p>Domanda: La valutazione della ricerca &#xE8; imparziale?</p>
<p>Risposta: La valutazione della ricerca &#xE8; imparziale quanto lo sono i suoi metodi e le tecniche di valutazione. Le metriche e le metriche alternative cercano di misurare la qualit&#xE0; della ricerca con la quantit&#xE0; del prodotto della ricerca, che pu&#xF2; essere accurata ma non lo &#xE8; sempre.</p>
<h2 id=""><img src="../Images/Icons/output.png" width="150" height="150"></h2>
<h3 id="risultati-dapprendimento">Risultati d&#x2019;apprendimento</h3>
<ol>
<li>I partecipanti sono in grado di identificare le riviste a revisione tra pari aperta.</li>
<li>I partecipanti imparano una serie di metriche con i relativi vantaggi e svantaggi.</li>
</ol>
<h2 id=""><img src="../Images/Icons/magnifying_glass.png" width="150" height="150"></h2>
<h3 id="letture-integrative">Letture integrative</h3>
<ul>
<li><p>Directorate-General for Research and Innovation (European Commission) (2017). Evaluation of Research Careers Fully Acknowledging Open Science Practices: Rewards, Incentives and/or Recognition for Researchers Practicing Open Science. <a href="https://doi.org/10.2777/75255" target="_blank">doi.org/10.2777/75255</a></p>
</li>
<li><p>Hicks et al. (2015) Bibliometrics: The Leiden Manifesto for research metrics. <a href="www.doi.org/10.1038/520429a">doi.org/10.1038/520429a</a>, <a href="http://www.leidenmanifesto.org/" target="_blank">leidenmanifesto.org</a></p>
</li>
<li><p>Peer Review the Nuts and Bolts (2012). A Guide for Early Career Researchers. <a href="http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf" target="_blank">PDF</a></p>
</li>
</ul>
<h3 id="progetti-ed-iniziative">Progetti ed iniziative</h3>
<ul>
<li><p>Make Data Count. <a href="https://makedatacount.org/" target="_blank">makedatacount.org</a></p>
</li>
<li><p>NISO Alternative Assessment Metrics (Altmetrics) Initiative. <a href="http://www.niso.org/standards-committees/altmetrics" target="_blank">niso.org</a></p>
</li>
<li><p>Open Rev. <a href="https://en.wikipedia.org/wiki/Open_Rev" target="_blank">openrev.org</a></p>
</li>
<li><p>OpenUP Hub. <a href="https://www.openuphub.eu/review" target="_blank">openuphub.eu</a></p>
</li>
<li><p>Peer Reviewers&#x2019; Openness Initiative. <a href="https://opennessinitiative.org/" target="_blank">opennessinitiative.org</a></p>
</li>
<li><p>Peerage of Science. A free service for scientific peer review and publishing. <a href="https://www.peerageofscience.org/" target="_blank">peerageofscience.org</a></p>
</li>
<li><p>Responsible Metrics. <a href="https://responsiblemetrics.org/" target="_blank">responsiblemetrics.org</a></p>
</li>
<li><p>Snowball Metrics. Standardized research metrics - by the sector for the sector. <a href="https://www.snowballmetrics.com/" target="_blank">snowballmetrics.com</a></p>
</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="07CollaborativePlatforms.html" class="navigation navigation-prev " aria-label="Previous page: Le piattaforme collaborative">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="09OpenSciencePolicies.html" class="navigation navigation-next " aria-label="Next page: Politiche e Scienza Aperta">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Revisione tra pari aperta, metriche e valutazione","level":"1.3.8","depth":2,"next":{"title":"Politiche e Scienza Aperta","level":"1.3.9","depth":2,"path":"02OpenScienceBasics/09OpenSciencePolicies.md","ref":"02OpenScienceBasics/09OpenSciencePolicies.md","articles":[]},"previous":{"title":"Le piattaforme collaborative","level":"1.3.7","depth":2,"path":"02OpenScienceBasics/07CollaborativePlatforms.md","ref":"02OpenScienceBasics/07CollaborativePlatforms.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["ga"],"pluginsConfig":{"ga":{"configuration":"auto","token":"UA-43664610-1"},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"02OpenScienceBasics/08OpenPeerReviewMetricsAndEvaluation.md","mtime":"2019-10-29T16:07:53.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-06-14T13:47:51.515Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-ga/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

